{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **03_DataExploration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* To conduct exploratory data analysis (EDA) to understand which factors are associated with XX to meet business requirement one (Client is interested in determining which demographic, lifestyle, medical and symptom factors are associated with clinical measures of disease, in terms of FEV1 and FVC)\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Raw data generated from \"01_DataCollection\". Saved as: inputs\\datasets\\raw\\asthma_disease_data.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate code that answers business requirement one, and can be used to build the Streamlit App"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy.stats import (\n",
        "    chi2_contingency,\n",
        "    fisher_exact,\n",
        "    mannwhitneyu,\n",
        "    ttest_ind,\n",
        "    shapiro\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data and drop \"DoctorInCharge\" as not needed for analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_raw_path = \"outputs/datasets/cleaned/asthma_disease_data_cleaned.csv\"\n",
        "df = pd.read_csv(df_raw_path)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Business requirement one focues on identifying the relationships between features and with the target variable (asthma status). \n",
        "\n",
        "Exploratory data analyses was performed for each feature, by asthma status. Additional exploratory analyses was performed to look at asthma patients by severity (defined by LungFunctionFEV1 and LungFunctionFVC), to assess feasibility of understanding asthma prognosis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the features and target (additional exploratory data analysis)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To assess feasibility of understanding severity of asthma patients, exploratory analyses was performed. Majority of the features in the dataset were not disease specific. Clinical factors, such as LungFunctionFEV1 and LungFunctionFVC were the most specific to asthma patients due to the underlying pathophysiology. For this reason, a \"LowLungFunction\" feature was created, based on \"severe\" ranges for FEV1 and FVC. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy of the dataframe for exploration of low lung function\n",
        "df_lung_function = df.copy()\n",
        "\n",
        "# Define threshold for low lung function (e.g., ≤ 1.5 L)\n",
        "threshold = 1.5\n",
        "\n",
        "# Create binary variable: 1 = low lung function, 0 = normal\n",
        "df_lung_function[\"LowLungFunction\"] = (\n",
        "    (df_lung_function[\"LungFunctionFEV1\"] <= threshold)\n",
        "    | (df_lung_function[\"LungFunctionFVC\"] <= threshold)\n",
        ").astype(int)\n",
        "\n",
        "print(\n",
        "    df_lung_function[\n",
        "        [\"LungFunctionFEV1\", \"LungFunctionFVC\", \"LowLungFunction\"]\n",
        "    ].head()\n",
        ")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "counts = df_lung_function[\"LowLungFunction\"].value_counts()\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "New feature was crosstabulated by asthma status:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crosstab: LowLungFunction vs Diagnosis\n",
        "counts_by_asthma = pd.crosstab(\n",
        "    df_lung_function[\"LowLungFunction\"], df_lung_function[\"Diagnosis\"]\n",
        ")\n",
        "\n",
        "print(counts_by_asthma)\n",
        "print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check whether low lung function is associated with asthma diagnosis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chi-square test\n",
        "chi2, p_value, dof, expected = chi2_contingency(counts_by_asthma)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2:.3f}\")\n",
        "print(f\"P-value (Chi-square test): {p_value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Low lung function was defined based on available criteria in the dataset; although a more clinical measure related to asthma, FEV1 and FVC percent predicted are more accurate, utilised measures in the real-world. Additionally, there was no significant association between low lung function and diagnosis, with a small pool for analysis (only n=12 asthma patients with low lung function). For this reason, further analysis regarding prediction of severe asthma and prognosis will not be performed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Descriptive statistics for continuous features (Age, BMI, PhysicalActivity, DietQuality, SleepQuality, DustExposure, PollutionExposure, PollenExposure, LungFunctionFEV1 and LungFunctionFVC)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loop over continuous features (float) and show a violin plot (amended from box plot to show distribution). No clear tails on violon plots for continuous features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "continuous_features = df.select_dtypes(include=\"float\").columns.tolist()\n",
        "\n",
        "fig, axes = plt.subplots(4, 3, figsize=(15, 16))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, feature in zip(axes, continuous_features):\n",
        "    sns.violinplot(\n",
        "        x=\"Diagnosis\",\n",
        "        y=feature,\n",
        "        data=df,\n",
        "        hue=\"Diagnosis\",\n",
        "        ax=ax,\n",
        "        inner=\"box\",\n",
        "        palette=\"Set2\",\n",
        "        legend=False,\n",
        "    )\n",
        "    ax.set_title(feature)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Descriptive statistics for binary (integer) features (Smoking, FamilyHistoryAsthma, PetAllergy, HistoryOfAllergies etc):\n",
        "---\n",
        "As the target and a subset of features are binary (0: No, 1: Yes), contingency tables were generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target = 'Diagnosis'\n",
        "binary_features = df.select_dtypes(include='int').columns.drop(target)\n",
        "\n",
        "encoding_maps = {\n",
        "    # Binary (0/1)\n",
        "    \"Gender\": {0: \"Male\", 1: \"Female\"},\n",
        "    \"Smoking\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"PetAllergy\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"FamilyHistoryAsthma\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"HistoryOfAllergies\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"Eczema\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"HayFever\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"GastroesophagealReflux\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"Wheezing\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"ShortnessOfBreath\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"ChestTightness\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"Coughing\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"NighttimeSymptoms\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"ExerciseInduced\": {0: \"No\", 1: \"Yes\"},\n",
        "    \"Diagnosis\": {0: \"No\", 1: \"Asthma\"},\n",
        "\n",
        "    # Multi-class categorical\n",
        "    \"Ethnicity\": {\n",
        "        0: \"Caucasian\",\n",
        "        1: \"African American\",\n",
        "        2: \"Asian\",\n",
        "        3: \"Other\"\n",
        "    },\n",
        "    \"EducationLevel\": {\n",
        "        0: \"None\",\n",
        "        1: \"High School\",\n",
        "        2: \"Bachelor's\",\n",
        "        3: \"Higher\"\n",
        "    }\n",
        "}\n",
        "\n",
        "contingency_tables = {}\n",
        "\n",
        "# Loop over features and create contingency tables\n",
        "for feature in binary_features:\n",
        "    # Map encoding\n",
        "    target_labels = df[target].map(encoding_maps.get(target, {}))\n",
        "    feature_labels = df[feature].map(encoding_maps.get(feature, {}))\n",
        "\n",
        "    # Contigency table targets\n",
        "    contingency = pd.crosstab(target_labels, feature_labels)\n",
        "    contingency_tables[feature] = contingency\n",
        "\n",
        "    print(f\"Contingency table: {target} vs {feature}\")\n",
        "    print(contingency)\n",
        "    print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bar charts to show the proportions amongst asthma and non-asthma patients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(4, 3, figsize=(15, 16))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, (feature, table) in zip(axes, contingency_tables.items()):\n",
        "    # Map the encoding\n",
        "    if feature in encoding_maps:\n",
        "        table = table.rename(columns=encoding_maps[feature])\n",
        "\n",
        "    # Convert counts to proportions\n",
        "    proportion_table = table.div(table.sum(axis=1), axis=0) * 100\n",
        "\n",
        "    # Plot grouped bar chart\n",
        "    proportion_table.plot(\n",
        "        kind=\"bar\", stacked=False, ax=ax, colormap=\"tab10\", legend=True\n",
        "    )\n",
        "    ax.set_title(feature)\n",
        "\n",
        "    ax.set_ylabel(\"Proportion (%)\")\n",
        "    ax.set_ylim(0, 100)\n",
        "    ax.legend(title=\"Legend\", fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ethnicity and education level have more than two categories. To be combined to maximise base size for analyses:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy of the dataframe\n",
        "df_updated = df.copy()\n",
        "\n",
        "# Replace Ethnicity values\n",
        "df_updated['Ethnicity'] = df_updated['Ethnicity'].replace({\n",
        "    0: 0,  # keep White as 0\n",
        "    1: 1,  # African American → 1\n",
        "    2: 1,  # Asian → 1\n",
        "    3: 1   # Other → 1\n",
        "})\n",
        "\n",
        "# Replace EducationLevel values\n",
        "df_updated['EducationLevel'] = df_updated['EducationLevel'].replace({\n",
        "    1: 1,  # Bachelor/Higher → 1\n",
        "    2: 1,  # Bachelor/Higher → 1\n",
        "    3: 0   # None/High school → 0\n",
        "})\n",
        "\n",
        "# Updated encoding maps\n",
        "encoding_maps_updated = encoding_maps.copy()  # start from original\n",
        "\n",
        "# Ethnicity: 0 = White, 1 = Others (collapsed African American, Asian, Other)\n",
        "encoding_maps_updated['Ethnicity'] = {\n",
        "    0: \"White\",\n",
        "    1: \"Other\"\n",
        "}\n",
        "\n",
        "# EducationLevel: 0 = None/High school, 1 = Bachelor/Higher\n",
        "encoding_maps_updated['EducationLevel'] = {\n",
        "    0: \"None/High School\",\n",
        "    1: \"Bachelor/Higher\"\n",
        "}\n",
        "\n",
        "df_updated.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_contingency = {}\n",
        "\n",
        "for col in ['Ethnicity', 'EducationLevel']:\n",
        "    table = pd.crosstab(target_labels, df_updated[col])\n",
        "    new_contingency[col] = table  # store in dict\n",
        "    print(f\"Contingency table: Diagnosis vs {col}\")\n",
        "    print(table)\n",
        "    print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, (feature, table) in zip(axes, new_contingency.items()):\n",
        "    # Map the updated encoding\n",
        "    if feature in encoding_maps_updated:\n",
        "        table = table.rename(columns=encoding_maps_updated[feature])\n",
        "\n",
        "    # Convert counts to proportions\n",
        "    proportion_table = table.div(table.sum(axis=1), axis=0) * 100\n",
        "\n",
        "    # Plot grouped bar chart\n",
        "    proportion_table.plot(\n",
        "        kind=\"bar\", stacked=False, ax=ax, colormap=\"tab10\", legend=True\n",
        "    )\n",
        "    ax.set_title(feature)\n",
        "\n",
        "    ax.set_ylabel(\"Proportion (%)\")\n",
        "    ax.set_ylim(0, 100)\n",
        "    ax.legend(title=\"Legend\", fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Statistical Analyses\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Continous features\n",
        "Association between continuous features and asthma diagnosis was testing using bivariate analyses, t-test or Mann-Whitney, based on normality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "continuous_features = df_updated.select_dtypes(\n",
        "    include=\"float\"\n",
        ").columns.tolist()\n",
        "\n",
        "# Create an empty dictionary for the results\n",
        "continuous_results = {}\n",
        "\n",
        "# Loop through features, ignore NaN data, and add significance finding\n",
        "for feature in continuous_features:\n",
        "    group0 = df_updated[df_updated[\"Diagnosis\"] == 0][feature].dropna()\n",
        "    group1 = df_updated[df_updated[\"Diagnosis\"] == 1][feature].dropna()\n",
        "\n",
        "    # Check normality\n",
        "    _, p0 = (\n",
        "        shapiro(group0) if len(group0) >= 3 else (None, 0)\n",
        "    )  # Shapiro requires ≥3 samples\n",
        "    _, p1 = shapiro(group1) if len(group1) >= 3 else (None, 0)\n",
        "\n",
        "    # Choose t-test if normal distribution, else Mann-Whitney\n",
        "    if p0 > 0.05 and p1 > 0.05:\n",
        "        stat, p = ttest_ind(\n",
        "            group0, group1, equal_var=False\n",
        "        )  # Welch's t-test\n",
        "        test_name = \"t-test\"\n",
        "    else:\n",
        "        stat, p = mannwhitneyu(group0, group1, alternative=\"two-sided\")\n",
        "        test_name = \"Mann-Whitney U\"\n",
        "\n",
        "    significance = \"Significant\" if p < 0.05 else \"Not significant\"\n",
        "\n",
        "    # Overview of the output\n",
        "    continuous_results[feature] = {\n",
        "        \"test\": test_name,\n",
        "        \"statistic\": stat,\n",
        "        \"p-value\": p,\n",
        "        \"significance\": significance,\n",
        "    }\n",
        "\n",
        "# Create a dataframe\n",
        "continuous_results_df = pd.DataFrame(continuous_results).T\n",
        "continuous_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Findings:\n",
        "* All continuous features were not normally distributed, meaning Mann-Whitney was performed.\n",
        "* The asthma and non‑asthma groups look statistically similar; no variable was statistically significant. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Binary features\n",
        "Association between binary features and asthma diagnosis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove diagnosis for analysis\n",
        "binary_features = [\n",
        "    col\n",
        "    for col in df_updated.select_dtypes(\"int\").columns\n",
        "    if col != \"Diagnosis\"\n",
        "]\n",
        "\n",
        "# Create an empty dictionary for the results\n",
        "binary_results = {}\n",
        "\n",
        "# Loop through features, recreate contigency tables, and significance\n",
        "for feature in binary_features:\n",
        "    table = pd.crosstab(df_updated[feature], df_updated[\"Diagnosis\"])\n",
        "\n",
        "    # Run chi-square test\n",
        "    chi2, p_chi, dof, expected = chi2_contingency(table)\n",
        "\n",
        "    # Decide whether to use Fisher (if any expected count < 5)\n",
        "    if (expected < 5).any():\n",
        "        oddsratio, p_value = fisher_exact(table)\n",
        "        test_used = \"Fisher's exact\"\n",
        "    else:\n",
        "        p_value = p_chi\n",
        "        oddsratio = (table.iloc[1, 1] / table.iloc[1, 0]) / (\n",
        "            table.iloc[0, 1] / table.iloc[0, 0]\n",
        "        )\n",
        "        test_used = \"Chi-square\"\n",
        "\n",
        "    # Significance\n",
        "    significance = \"Significant\" if p_value < 0.05 else \"Not significant\"\n",
        "\n",
        "    # Overview of the output\n",
        "    binary_results[feature] = {\n",
        "        \"test\": test_used,\n",
        "        \"p-value\": p_value,\n",
        "        \"odds_ratio\": oddsratio,\n",
        "        \"significance\": significance,\n",
        "    }\n",
        "\n",
        "# Create a dataframe\n",
        "binary_results_df = pd.DataFrame(binary_results).T\n",
        "binary_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most binary features showed no significant association with asthma status. The exception was ExcerciseInduced, which showed a statistically significant association, with an odds ratio of 1.7. This indicates that exercise induced symptoms were 1.7 times more likely to be reported by patients with asthma. Exercise induced asthma is a known disease subtype, and may be reflected here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature-Target Correlation Matrix\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The feature‑correlation matrix summarises linear relationships between variables, highlighting potential associations and areas of multicollinearity. \n",
        "* Correlation values range from –1 (strong negative relationship) to +1 (strong positive relationship), with values near 0 indicating weak or no linear association.\n",
        "\n",
        "Because asthma prevalence in the dataset is very low, correlations involving the target variable remain small—an expected limitation when analysing highly imbalanced outcomes. Note, Power Predictive Score (PPS) was not used here due to package conflicts that prevented reliable computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = df_updated.drop([\"Diagnosis\"], axis=1)\n",
        "target = df_updated[\"Diagnosis\"]\n",
        "\n",
        "correlation_matrix = features.corrwith(target)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    pd.DataFrame(correlation_matrix, columns=[\"Correlation\"]),\n",
        "    annot=True,\n",
        "    cmap=\"coolwarm\",\n",
        "    cbar=True,\n",
        ")\n",
        "plt.title(\"Feature-Target Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Push files to repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the updated dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    os.makedirs('outputs/datasets/cleaned', exist_ok=True)  \n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "df.to_csv(\"outputs/datasets/cleaned/asthma_disease_data_amended.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train and Test Set\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split the database, based on code from the \"churnometer\" walkthough example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_updated.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df_updated,\n",
        "                                        df_updated['Diagnosis'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Push the train and test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs(\"outputs/datasets/cleaned\", exist_ok=True)\n",
        "\n",
        "# Train set\n",
        "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)\n",
        "\n",
        "# Test set\n",
        "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion and Next Steps\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To answer Business Question One, initial bivariate analyses was performed to understand the distribution of data and the relationships between the target (Diagnosis) and features.\n",
        "\n",
        "Continuous features were visualized using violin plots to understand distribution. In this dataset, most features showed overlapping violin shapes with no clear tails.  Shapiro-Wilk test was used to test the distrubiton of continuous features; as all features passed the distrubution test, non-parametric (Mann-Whitney) test was performed. No continuous features were significantly associated with asthma status (Diagnosis).\n",
        "\n",
        "Additionally, contigency tables were generated for binary features, alongside bar charts. Due to the low bases for specific subgroups, groups were combined to maximize bases for EducationLevel and Ethnicity (two categories for both). Chi-square test wad performed for all features; ExerciseInduced was significantly associated with asthma status (Diagnosis).\n",
        "\n",
        "Train and test sets were generated for feature engineering and modeling. \n",
        "\n",
        "Next steps:\n",
        "* Prepare data for feature engineering and modeling, to answer Business Requirement Two."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
